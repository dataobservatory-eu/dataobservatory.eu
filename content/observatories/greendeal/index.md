---
title: Green Deal Data Observatory
summary: An ambitious project to connect environmental sensory data, political and policy survey data with socio-economic indicators.
tags:
- climate-change

date: "2021-07-07T00:00:00Z"
lastmod: "2021-07-11T00:00:00Z"

# Optional external URL for project (replaces project detail page).
external_link: ""

image:
  caption: "Diamond Polisher, ©[Andere Andre](https://commons.wikimedia.org/w/index.php?curid=4770037)"
  focal_point: Center

links:
- icon: twitter
  icon_pack: fab
  name: Follow
  url: https://twitter.com/GreenDealObs
- icon: linkedin
  icon_pack: fab
  name: Connect
  url: https://www.linkedin.com/company/78562153/
- icon: telescope
  icon_pack: fas
  name: Green Deal Data Observatory
  url: https://greendeal.dataobservatory.eu/
- icon: database
  icon_pack: fas
  name: Try API
  url: https://api.greendeal.dataobservatory.eu/
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---

**Finding reliable, recent, new data and information about climate change, and the impact of various policies in the European Green Deal that try to mitigate it is surprisingly hard to find if you are scientific researcher. And it is even more hopeless if you work as a (data) journalist, a policy researcher in an NGO, or in the sustainability unit of a company that does not provide you with an army of (geo)statisticians, data engineers and scientist to put various data into usable format. Something that you can trust, quote, visualize, import or copy & paste.**

<td style="text-align: center;">{{< figure src="/media/img/blogposts_2021/global_problem_1_climate_change_5_plots.png" caption="**Novel data products**: Official statistics on national and European level follow legal regulations, and in the EU, compromises between member states.  New policy indicators often appear 5-10 years after the year arises. We use the same methodology, and peer-reviewed statistical software to process it, often the same data, that Eurostat would use, but we can create the new indicator…. Now. See our example [100,000 Opinions on the Most Pressing Global Problem](https://greendeal.dataobservatory.eu/post/2021-11-19_global_problem/)." numbered="false" >}}</td>

<td style="text-align: center;">{{< figure src="/media/img/blogposts_2021/noaa-WWVD4wXRX38-unsplash-edited.png" caption="**Better data**:  Statistical agencies, old fashioned observatories, data providers often do not have the mandate, know-how or resources to improve data quality. Using peer-reviewed statistical software, hundreds of computational tests, we correct mistakes, make correct imputations and forecasts, and we increase the information content of public data by 20-200% percent. This makes the data usable for NGOs, journalist, visual artists who do not have this statistical know-how to make patchy data usable for their application. See our example with the indicator [Government Budget Allocations for R&D in Environment](https://greendeal.dataobservatory.eu/post/2021-11-08-indicator_value_added/)" numbered="false" >}}</td>

<td style="text-align: center;">{{< figure src="/media/img/blogposts_2021/Gold_panning_at_Bonanza_Creek_4x6.png" caption="**Never seen data**: The 2019/1024 directive on open data and the re-use of public sector information of the European Union (and the earlier regulation that has been in force since 2003) makes data gathered in EU institutions, national institutions and municipalities, state owned companies at a cost of billions of euros legally available. But if this is a gold mine, you need data mining partner like us, because the data is not downloadable, sits in various obsolete file formats, in disorganized databases, documented in various languages, or not documented at all, plagued with various processing errors. We make [the powerful promise](http://dataobservatory.eu/post/2021-06-18-gold-without-rush/) of the EU legislation a reality in the field of the green deal policy context." numbered="false">}}</td>

Reprex helps its policy, business and scientific partners with these tedious data engineering, data processing and statistical task. We deploy validated, open-source, peer-reviewed scientific software to create up-to-date, reliable, high-quality, immediately usable data and visualizations. Our partners can leave the burden of this task, share the cost of data processing, and concentrate on what they do best: disseminating and advocating, researching, or setting sustainable business or underwriting indicators, creating early warning systems. 

<td style="text-align: center;">{{< figure src="/media/img/belgium_flood_risk.jpg" caption="**Impact**: We publish the data in a way that it is easy to find---as a separate data publication with a DOI, full library information data, placed in open science repositories. Our data is more finable than 99% of the open science data, and therefore makes far bigger impact." numbered="false" >}}</td>

<td style="text-align: center;">{{< figure src="/media/img/blogposts_2021/Sisyphus_Bodleian_Library.png" caption="**Easy-to-use data**:  Our data follows the tidy data principle and comes with all the recommended Dublin Core and DataCite metadata. This makes our data particularly easy to open in any spreadsheet application or import into your own database. We publish the data in tabular form, and in JSON form on our API which allows automatic retrieval for heavy users. This is also the best guarantee against repeating the same steps – downloading, changing layout in Excel or OpenOffice or Numbers, removing % signs, properly documenting file versions and their contents (who does *that*?) and other data processing steps that take up hours and in larger hours thousands of working hours. See our blogpost on the [data Sisyphus](https://greendeal.dataobservatory.eu/post/2021-07-08-data-sisyphus/)." numbered="false" >}}</td>

Big data creates inequalities, because only the largest corporations, government bureaucracies and best endowed universities can afford large data collection programs, the use of satellites, and employ many data scientists. Our open collaboration method to pool the data, share the costs makes big data available for all. 

<td style="text-align: center;">{{< figure src="/media/img/blogposts_2021/belgium_problem_maps.png" caption="**Big picture**: Integrating and joining data is hard---it requires engineering, mathematical or geo-statistical know-how that most environmental users do not possess. Changing boundaries of French departments, various projections of coordinates on satellite images of land cover, different measurement areas for public opinion and hydrological data, public finance in millions or thousands of euros. We create data that is easy to combine, map, visualize for the end user. See our case study on the severity, awareness of flood risk in Belgium and financial capacity to manage it in our [case study for Belgium](https://greendeal.dataobservatory.eu/post/2021-04-23-belgium-flood-insurance/)." numbered="false" >}}</td>

<td style="text-align: center;">{{< figure src="/media/img/blogposts_2021/firing_squad.png" caption="**Ethical, Trustworthy AI for All**: AI in 2021 increases data inequalities because large government and corporate entities with an army of data engineers can create business proprietary, black box algorithms that fundamentally alter our lives. We are involved in the R&D and advocacy of the EU’s trustworthy AI agenda which aims at similar protections like GDPR in privacy. We want to demystify AI by making it available for organizations who cannot finance a data engineering team, because 95% of a successful AI is cheap, complete, reliable data tested for negative outcomes – precisely what [we offer](https://dataandlyrics.com/post/2021-05-16-recommendation-outcomes/) to our users." numbered="false" >}}</td>







 